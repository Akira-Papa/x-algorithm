# 第4章：Phoenix MLモデルの内部構造

## 4.1 機械学習ランキングとは

Phoenix（フェニックス）は、Xの推薦システムにおける「頭脳」です。機械学習モデルを用いて、各投稿が各ユーザーに対してどれだけ価値があるかを予測します。

従来のランキングシステムは、「いいね数が多い順」「新しい順」といった単純なルールで並べ替えていました。しかし、Phoenixは違います。

```
【従来のランキング vs Phoenix】

従来のランキング:
投稿A: いいね100 → スコア100
投稿B: いいね50  → スコア50
→ 投稿Aが上位

Phoenix MLランキング:
投稿A: ユーザーXがいいねする確率 30%
       ユーザーXがリプライする確率 2%
       ユーザーXがプロフを見る確率 5%
       → 重み付き合計スコア: 85

投稿B: ユーザーXがいいねする確率 40%
       ユーザーXがリプライする確率 15%
       ユーザーXがプロフを見る確率 20%
       → 重み付き合計スコア: 142

→ 投稿Bが上位（いいねは少ないが、深いエンゲージメントが期待される）
```

つまり、Phoenixは「この投稿が過去にどれだけ反応を集めたか」ではなく、「この投稿を見た**あなた**がどう反応するか」を予測しているのです。

---

## 4.2 Phoenix Transformerの構造

Phoenixの中核は、**Grok Transformer**と呼ばれる深層学習モデルです。

### 全体アーキテクチャ

```
【Phoenix Transformer 全体構造】

入力層
┌─────────────────────────────────────────────────────────┐
│  User Features    │  Tweet Features   │  Author Features │
│  （256次元）       │  （512次元）       │  （128次元）      │
│                   │                   │                   │
│  - 過去の行動     │  - テキスト埋め込み │  - フォロワー数   │
│  - 興味カテゴリ   │  - メディア特徴    │  - 投稿頻度      │
│  - フォロー関係   │  - エンゲージ履歴  │  - エンゲージ率   │
└─────────────────────────────────────────────────────────┘
                              ↓
                    ┌─────────────────┐
                    │ Context Features │
                    │   （64次元）      │
                    │                  │
                    │  - 時刻          │
                    │  - デバイス      │
                    │  - 言語          │
                    └─────────────────┘
                              ↓
中間層（Grok Transformer）
┌─────────────────────────────────────────────────────────┐
│                                                         │
│          Transformer Encoder（8層）                     │
│                                                         │
│  ┌─────────────────────────────────────────────────┐   │
│  │ Multi-Head Self-Attention（16ヘッド）           │   │
│  │ + Candidate Isolation（候補分離機構）           │   │
│  └─────────────────────────────────────────────────┘   │
│                         ↓                               │
│  ┌─────────────────────────────────────────────────┐   │
│  │ Feed-Forward Network（1024次元）               │   │
│  │ + Dropout（0.1）                               │   │
│  └─────────────────────────────────────────────────┘   │
│                         ↓                               │
│          （これを8回繰り返し）                          │
│                                                         │
└─────────────────────────────────────────────────────────┘
                              ↓
出力層
┌─────────────────────────────────────────────────────────┐
│          19種類のエンゲージメント確率                    │
│                                                         │
│  favorited_prob:     0.35  │  profile_clicked_prob: 0.08│
│  retweeted_prob:     0.12  │  followed_prob:        0.02│
│  replied_prob:       0.05  │  video_quality_view:   0.15│
│  quoted_prob:        0.03  │  ...（計19種類）           │
└─────────────────────────────────────────────────────────┘
```

### 数値で見るPhoenix

```python
# recsys_model.py から抽出したモデル構造

class PhoenixModel:
    # 入力特徴量の次元数
    user_embedding_dim = 256
    tweet_embedding_dim = 512
    author_embedding_dim = 128
    context_embedding_dim = 64

    # Transformer設定
    num_layers = 8           # 8層のTransformer
    num_attention_heads = 16 # 16個のAttentionヘッド
    hidden_dim = 1024        # 隠れ層の次元数
    dropout_rate = 0.1       # ドロップアウト率

    # 出力
    num_engagement_types = 19  # 19種類の確率出力
```

---

## 4.3 Candidate Isolation：公平な評価

Phoenixの最も特徴的な技術が**Candidate Isolation（候補分離）**です。

### なぜ候補分離が必要か

通常のTransformerでは、入力されたすべての要素が互いに情報を交換します。しかし、推薦システムでこれを行うと問題が発生します。

```
【候補分離なしの問題】

候補投稿A、B、Cを同時にスコアリングする場合：

通常のTransformer:
  A ←→ B ←→ C（互いに情報交換）

問題1: 順序バイアス
  - Aが最初にあるから有利、Cが最後だから不利
  - 入力順序で結果が変わってしまう

問題2: 競合バイアス
  - AがBより「良く見える」とBのスコアが下がる
  - 相対評価になってしまう

問題3: 情報漏洩
  - Aの内容がBのスコアリングに影響
  - 独立した評価ができない
```

### Candidate Isolationの仕組み

```
【Candidate Isolation の動作】

Phoenix Transformer with Candidate Isolation:

  候補A → ユーザー特徴 ← 候補B
  候補B → ユーザー特徴 ← 候補C
  候補C → ユーザー特徴 ← 候補A

  ※ 候補同士は直接見えない
  ※ ユーザー特徴のみを参照

実装（grok.py より）:
┌─────────────────────────────────────────────────────────┐
│ Attention Mask:                                         │
│                                                         │
│         A    B    C   User                             │
│    A [  1    0    0    1  ]  ← Aは自分とUserだけ見える │
│    B [  0    1    0    1  ]  ← Bは自分とUserだけ見える │
│    C [  0    0    1    1  ]  ← Cは自分とUserだけ見える │
│ User[  1    1    1    1  ]  ← Userは全部見える        │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

### 戦略的含意

この仕組みが意味する重要なことがあります：

> **あなたの投稿は、他の候補投稿と「競争」しているのではありません。**

アルゴリズムは、あなたの投稿を「このユーザーにとって、どれだけ価値があるか」で独立して評価しています。つまり：

```
【Candidate Isolationの戦略的含意】

誤解:
「今、バズっている投稿と競争している」
「有名人の投稿があるから、自分の投稿は埋もれる」

正解:
「自分の投稿が、このユーザーの興味にマッチするかが勝負」
「他の投稿の存在は、自分のスコアに影響しない」
```

これは非常に重要な理解です。他者との競争ではなく、**ターゲットユーザーとのマッチング**に集中すべきなのです。

---

## 4.4 予測から表示までの流れ

Phoenixがスコアを計算した後、どのように表示が決まるかを見ていきましょう。

```
【予測から表示までの流れ】

Step 1: 特徴量抽出
┌─────────────────────────────────────────────────────────┐
│ ユーザーAさんがXを開いた                                │
│                                                         │
│ → ユーザーAの特徴量を取得（User Features）             │
│ → 候補投稿1000件を取得                                 │
│ → 各候補の特徴量を取得（Tweet/Author Features）        │
└─────────────────────────────────────────────────────────┘
                              ↓
Step 2: Phoenix推論
┌─────────────────────────────────────────────────────────┐
│ 1000件の候補それぞれに対して：                          │
│                                                         │
│ 候補1: [いいね確率:0.35, リプライ確率:0.08, ...]       │
│ 候補2: [いいね確率:0.22, リプライ確率:0.15, ...]       │
│ ...                                                     │
│ 候補1000: [いいね確率:0.18, リプライ確率:0.03, ...]    │
└─────────────────────────────────────────────────────────┘
                              ↓
Step 3: 重み付きスコア計算
┌─────────────────────────────────────────────────────────┐
│ 各候補の最終スコア = Σ(確率 × 重み)                    │
│                                                         │
│ 候補1: 0.35×0.5 + 0.08×13.5 + ... = 85.2              │
│ 候補2: 0.22×0.5 + 0.15×13.5 + ... = 142.7             │
│ ...                                                     │
└─────────────────────────────────────────────────────────┘
                              ↓
Step 4: 追加スコアラー適用
┌─────────────────────────────────────────────────────────┐
│ OON Scorer: フォロー外なら × 0.85                      │
│ Author Diversity: 同一著者連続なら × 0.95^n           │
│ VQV Scorer: 動画品質視聴なら × 1.5                    │
└─────────────────────────────────────────────────────────┘
                              ↓
Step 5: 最終ランキング
┌─────────────────────────────────────────────────────────┐
│ 1位: 候補2（スコア: 142.7）                            │
│ 2位: 候補15（スコア: 138.2）                           │
│ 3位: 候補1（スコア: 85.2）                             │
│ ...                                                     │
│ → 上位50件をタイムラインに表示                        │
└─────────────────────────────────────────────────────────┘
```

---

## 4.5 MLモデルが意味する戦略的含意

Phoenixの仕組みを理解した上で、戦略的な含意を考えましょう。

### 含意1：パーソナライゼーションは絶対

```
【パーソナライゼーションの現実】

同じ投稿でも、見る人によってスコアが全く異なる

投稿「SaaS成長戦略について」:
- SaaSマーケター向け → スコア: 180
- 料理好き主婦向け   → スコア: 12

→ ターゲットを絞るほど、そのターゲットでのスコアは上がる
→ 「全員に届けたい」は「誰にも届かない」になりがち
```

### 含意2：予測されるのは「あなたの反応」

```
【予測対象の理解】

アルゴリズムが予測しているのは:
✗ 「この投稿は一般的に良い投稿か」
○ 「この投稿を見たあなたは、どう反応するか」

含意:
- 過去の反応パターンが重要
- 「刺さる人」には高スコア、「刺さらない人」には低スコア
- ニッチでも、刺さる人に届けば成功
```

### 含意3：19種類の確率すべてが計算される

```
【19種類の予測】

あなたの投稿に対して、毎回19種類の確率が計算される:
- いいねする確率
- リポストする確率
- リプライする確率
- プロフィールを見る確率
- フォローする確率
- 通報する確率
- ...

含意:
- 「いいねされやすい」だけでは不十分
- 「リプライされやすい」「プロフィール見られやすい」を狙う
- 「通報されにくい」も同時に満たす必要
```

---

## 4.6 この章のまとめ

```
【第4章 重要ポイント】

✓ PhoenixはGrok Transformerベースの機械学習モデル
  → 8層、16アテンションヘッド、1024次元

✓ Candidate Isolationで候補を独立評価
  → 他の投稿との「競争」ではなく「マッチング」

✓ 19種類のエンゲージメント確率を予測
  → 重み付き合計が最終スコア

✓ パーソナライゼーションは絶対
  → 同じ投稿でも、見る人によってスコアは全く異なる
```

```
【今日からできること】

□ ターゲットを明確に絞る（全員に届けようとしない）
□ リプライ・プロフィールクリックを誘発する内容を意識
□ 他の投稿との競争ではなく、ターゲットとのマッチングに集中
□ ネガティブエンゲージメントの確率を下げる（攻撃的な内容を避ける）
```

---

**次章予告**: 第5章では、Phoenixの予測スコアがどのように他のスコアラーと組み合わされるか、スコアリングシステムの全体像を解説します。

---

[← 第3章に戻る](./chapter-03-two-tower.md) | [目次](./README.md) | [第5章へ進む →](./chapter-05-scoring.md)
